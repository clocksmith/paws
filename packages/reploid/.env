# Reploid Configuration
# This file is used to configure the Reploid server

# Auto-start Ollama when the server starts (set to false since it's already running)
AUTO_START_OLLAMA=false

# Server Configuration
PORT=8000

# Local Model Configuration (Ollama)
LOCAL_MODEL_ENDPOINT=http://localhost:11434

# Default local model to use
DEFAULT_LOCAL_MODEL=gpt-oss:120b

# Optional: Add API keys for cloud providers if you want to use them
GEMINI_API_KEY=AIzaSyBdk4DHKZYmIQ0jLvNU82EmW_OjULZdsn4
# OPENAI_API_KEY=your_key_here
# ANTHROPIC_API_KEY=your_key_here
